{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0043286e",
   "metadata": {},
   "source": [
    "**TUTORIAL**\n",
    "\n",
    "This Notebook guides the reader through the various steps required for the full-pandemic calibration of the spatially explicit SEIQRD model with VOCs, vaccinations, and seasonality.\n",
    "\n",
    "**Remaining Problems and Errors**\n",
    "- If `processes` is not equal to one, the `multiprocessing` unit is activated, which _sometimes_ but not always ceases functionality. It appears do hinder functionality especially when the execution is computationally heavy. Using just one core is possible, but takes approx 4 minutes per iteration. The complete-calibration MCMC runs for a little while, but than stops working altogether (without crashing)\n",
    "- When executing the PSO and MCMC, the following warning often appears: \"invalid value encountered in double_scalars\", which I assume has to do with the fact that some values exit their boundary conditions when their initial value is perturbed at the start of the MCMC chain.\n",
    "- Another warning often appears, which has to do with the depreciated 'freq' option in pandas Timestamp objects. This is not very important, however.\n",
    "- I cannot run the MCMC with only 1 core, because then the number of parameters is equal to the number of MCMC chains, and the error will apear that the chains are linearly dependent.\n",
    "\n",
    "**Remaining Questions and Hunches for Problem Solutions**\n",
    "- Make sure that the order of provinces defined in the data is the same as the order defined in e.g. `initial_state`\n",
    "- The `policies_all` function that governs the social contact is defined differently for pre-pandemic times than e.g. `policies_WAVE1`. This may cause some issues, according to Tijs.\n",
    "- Can the MCMC perhaps also look over various values for `warmup`, rather than only the PSO?\n",
    "- It's probably best to simply use the seasonality parameter values (`amplitude` and `peak_shift`) from the national calibration, because two additional parameters make the calculations even more tedious\n",
    "- \n",
    "\n",
    "**Research Opportunities**\n",
    "- Stratify `Nc` at provincial level\n",
    "- O2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed80ebf9",
   "metadata": {},
   "source": [
    "# Load required packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf316b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:04.128618Z",
     "start_time": "2021-10-06T11:55:02.108602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load standard packages\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Import the spatially explicit SEIQRD model with VOCs, vaccinations, seasonality\n",
    "from covid19model.models import models\n",
    "\n",
    "# Import function to easily define the spatially explicit initial condition\n",
    "from covid19model.models.utils import initial_state\n",
    "\n",
    "# Import time-dependent parameter functions for resp. P, Nc, alpha, N_vacc, season_factor\n",
    "from covid19model.models.time_dependant_parameter_fncs import make_mobility_update_function, \\\n",
    "                                                              make_contact_matrix_function, \\\n",
    "                                                              make_VOC_function, \\\n",
    "                                                              make_vaccination_function, \\\n",
    "                                                              make_seasonality_function\n",
    "\n",
    "# Import packages containing functions to load in data used in the model and the time-dependent parameter functions\n",
    "from covid19model.data import mobility, sciensano, model_parameters, VOC\n",
    "\n",
    "# Import function associated with the PSO and MCMC\n",
    "from covid19model.optimization import pso, objective_fcns\n",
    "from covid19model.optimization.objective_fcns import prior_custom, prior_uniform\n",
    "from covid19model.optimization.utils import perturbate_PSO, run_MCMC, assign_PSO, plot_PSO\n",
    "\n",
    "# Load the \"autoreload\" extension so that package code can change\n",
    "%load_ext autoreload\n",
    "# Always reload modules so that as you change code in src, it gets loaded\n",
    "# This may be useful because the `covid19model` package is under construction\n",
    "%autoreload 2\n",
    "\n",
    "################################################\n",
    "### Determine geographical aggregation level ###\n",
    "################################################\n",
    "\n",
    "agg='prov'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d960f1b8",
   "metadata": {},
   "source": [
    "# Load required data and initialise functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa7cfb3",
   "metadata": {},
   "source": [
    "## Dictionaries and DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a0617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:07.400835Z",
     "start_time": "2021-10-06T11:55:04.129583Z"
    }
   },
   "outputs": [],
   "source": [
    "# Total population and contact matrices for the correct aggregation level\n",
    "initN, Nc_all = model_parameters.get_integrated_willem2012_interaction_matrices(spatial=agg)\n",
    "\n",
    "# Google Mobility data (for social contact Nc)\n",
    "df_google = mobility.get_google_mobility_data(update=False)\n",
    "\n",
    "# Load and format mobility dataframe (for mobility place)\n",
    "proximus_mobility_data, proximus_mobility_data_avg = mobility.get_proximus_mobility_data(agg, dtype='fractional', beyond_borders=False)\n",
    "\n",
    "# Load and format national VOC data (for time-dependent VOC fraction)\n",
    "df_VOC_abc = VOC.get_abc_data()\n",
    "\n",
    "# Load and format local vaccination data, which is also under the sciensano object\n",
    "public_spatial_vaccination_data = sciensano.get_public_spatial_vaccination_data(update=False,agg=agg)\n",
    "\n",
    "# All 36 parameters associated with the full model\n",
    "params = model_parameters.get_COVID19_SEIRD_parameters(spatial=agg, vaccination=True,VOC=True)\n",
    "\n",
    "# Raw local hospitalisation data used in the calibration. Moving average disabled for calibration\n",
    "values = 'hospitalised_IN'\n",
    "df_sciensano = sciensano.get_sciensano_COVID19_data_spatial(agg=agg, values=values, moving_avg=False)\n",
    "\n",
    "\n",
    "# SANITY CHECK: plot the full dataframe per province\n",
    "fig,ax=plt.subplots(figsize=(16,4))\n",
    "df_sciensano.plot(kind='area', stacked=True,ax=ax)\n",
    "ax.set_ylabel('New daily hospitalisations', fontsize=14)\n",
    "\n",
    "# Invert order of legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "leg=ax.legend(handles[::-1], labels[::-1], loc='upper right', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592d8ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:07.509057Z",
     "start_time": "2021-10-06T11:55:07.401833Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sciensano.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694bebb",
   "metadata": {},
   "source": [
    "## Time-dependent parameter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df45bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:07.835185Z",
     "start_time": "2021-10-06T11:55:07.512050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time-dependent social contact matrix over all policies, updating Nc\n",
    "policy_function = make_contact_matrix_function(df_google, Nc_all).policies_all\n",
    "\n",
    "# Time-dependent mobility function, updating P (place)\n",
    "mobility_function = make_mobility_update_function(proximus_mobility_data, proximus_mobility_data_avg).mobility_wrapper_func\n",
    "\n",
    "# Time-dependent VOC function, updating alpha\n",
    "VOC_function = make_VOC_function(df_VOC_abc)\n",
    "\n",
    "# Time-dependent (first) vaccination function, updating N_vacc\n",
    "vaccination_function = make_vaccination_function(public_spatial_vaccination_data, spatial=True)\n",
    "\n",
    "# Time-dependent seasonality function, updating season_factor\n",
    "seasonality_function = make_seasonality_function()\n",
    "\n",
    "\n",
    "# SANITY CHECK: plot the vaccination per province\n",
    "dates_vacc = pd.date_range(start = '2021-01-01', end = '2021-09-01', freq='W-MON')\n",
    "vaccs_prov=[]\n",
    "for date in dates_vacc:\n",
    "    vacc_prov = vaccination_function.get_sciensano_spatial_first_dose(date).sum(axis=1)\n",
    "    vaccs_prov.append(vacc_prov)\n",
    "vaccs_prov=np.array(vaccs_prov).cumsum(axis=0)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(16,4))\n",
    "ax.grid(False)\n",
    "labels = ['Antwerpen', 'Vlaams-Brabant', 'Waals-Brabant', 'Brussels', 'West-Vlaanderen', 'Oost-Vlaanderen',\\\n",
    "          'Hainaut', 'Li√®ge', 'Limburg', 'Luxembourg', 'Namur']\n",
    "ax.stackplot(dates_vacc, vaccs_prov[:,0],\\\n",
    "             vaccs_prov[:,1],\\\n",
    "             vaccs_prov[:,2],\\\n",
    "             vaccs_prov[:,3],\\\n",
    "             vaccs_prov[:,4],\\\n",
    "             vaccs_prov[:,5],\\\n",
    "             vaccs_prov[:,6],\\\n",
    "             vaccs_prov[:,7],\\\n",
    "             vaccs_prov[:,8],\\\n",
    "             vaccs_prov[:,9],\\\n",
    "             vaccs_prov[:,10],\\\n",
    "             labels=labels)\n",
    "ax.tick_params('x', labelrotation=30)\n",
    "ax.set_title('First vaccination dose per province')\n",
    "\n",
    "# Invert order of legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "leg=ax.legend(handles[::-1], labels[::-1], loc='upper left', fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64910561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T13:38:39.162127Z",
     "start_time": "2021-09-16T13:38:39.085971Z"
    }
   },
   "source": [
    "# Initialise model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd220b9",
   "metadata": {},
   "source": [
    "## Pre-pandemic initial condition\n",
    "\n",
    "The initial condition determines how many people are exposed initially, as well as their position and their age. As in the wave-1 calibration, we opt for an initial condition with the following properties:\n",
    "1. A total of 3 subjects\n",
    "2. All aged between 40 and 50\n",
    "3. Spread equally over all provinces, scaled by the relative number of hospitalisations in each region on March 20th 2020.\n",
    "\n",
    "Note that this implies that there will be e.g. 0.437 people in Antwerp as an initial condition. Fractional people pose no problem for our model. Other variations are possible: see the documentation of `initial_state` by executing `initial_state?`\n",
    "\n",
    "**@TIJS**: This initial condition is _data-inspired but hard-coded_. This can be varied over in a calibration procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67a1af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:07.989771Z",
     "start_time": "2021-10-06T11:55:07.836182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define properties of subjects in initial condition\n",
    "init_number = 3\n",
    "age=40\n",
    "dist='frac'\n",
    "\n",
    "# Define the matrix of exposed subjects that will be identified with compartment E\n",
    "initE = initial_state(dist='frac', agg=agg, age=age, number=init_number)\n",
    "\n",
    "# Add the susceptible and exposed population to the initial_states dict\n",
    "initial_states = {'S': initN-initE, 'E': initE}\n",
    "\n",
    "# SANITY CHECK: the sum should be init_number\n",
    "print(f'Total number of initially exposed subjects: {initE.sum()}\\r')\n",
    "\n",
    "# Verify with inhabitants of provinces to convince yourself further if needed\n",
    "# inhabitants = pd.read_csv('../../data/raw/GIS/inhabitants.csv')\n",
    "# inhabitants[inhabitants['NIS']==10000]['inhabitants'].values[0]\n",
    "\n",
    "initial_states['E']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef605a3",
   "metadata": {},
   "source": [
    "## Addition of parameters required in the time-dependent parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee9010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:08.283391Z",
     "start_time": "2021-10-06T11:55:07.990769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload params first (not necessary but often useful)\n",
    "params = model_parameters.get_COVID19_SEIRD_parameters(spatial=agg, vaccination=True,VOC=True)\n",
    "\n",
    "# time-dependent social contact parameters in policies_function\n",
    "params.update({'l1' : 5,\n",
    "               'l2' : 5,\n",
    "               'prev_schools' : 0,\n",
    "               'prev_work' : .5,\n",
    "               'prev_rest_lockdown' : .5,\n",
    "               'prev_rest_relaxation' : .5,\n",
    "               'prev_home' : .5})\n",
    "\n",
    "# time-dependent mobility parameters in mobility_function\n",
    "params.update({'default_mobility' : None})\n",
    "\n",
    "# time-dependent vaccination parameters in vaccination_function\n",
    "params.update({'initN' : initN,\n",
    "               'daily_first_dose' : 60000, # copy default values from vaccination_function, which are curently not used I think\n",
    "               'delay_immunity' : 14,\n",
    "               'vacc_order' : [8, 7, 6, 5, 4, 3, 2, 1, 0],\n",
    "               'stop_idx' : 9,\n",
    "               'refusal' : [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]})\n",
    "\n",
    "# time-dependent seasonality parameters in seasonality_function\n",
    "params.update({'season_factor' : 1,\n",
    "               'amplitude' : 0.1,\n",
    "               'peak_shift' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def088c",
   "metadata": {},
   "source": [
    "## Actual initialisation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36cb2c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:14.566531Z",
     "start_time": "2021-10-06T11:55:08.284365Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.COVID19_SEIRD_spatial_vacc(initial_states, params, spatial=agg,\n",
    "                        time_dependent_parameters={'Nc' : policy_function,\n",
    "                                                   'place' : mobility_function,\n",
    "                                                   'N_vacc' : vaccination_function, \n",
    "                                                   'alpha' : VOC_function,\n",
    "                                                   'season_factor' : seasonality_function})\n",
    "\n",
    "# SANITY CHECK: plot output with default values, just to see if there is *any* output\n",
    "warmup = 10\n",
    "start_sim = '2020-03-05' # First available data\n",
    "end_sim = '2022-01-01' # Three months ahead\n",
    "out = model.sim(end_sim,start_date=start_sim,warmup=warmup)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(16,4))\n",
    "graph=out['H_in'].sum(dim='Nc').sum(dim='place').plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89633d4",
   "metadata": {},
   "source": [
    "# Calibration of the _warmup_ value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a976c5",
   "metadata": {},
   "source": [
    "## Technical setup\n",
    "\n",
    "@TIJS: if `processes` is not 1, this enters an infinite loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f229a92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:14.659648Z",
     "start_time": "2021-10-06T11:55:14.567530Z"
    }
   },
   "outputs": [],
   "source": [
    "### PSO settings\n",
    "\n",
    "# Hard-code number of cores used\n",
    "# processes = 2\n",
    "# Find number of available cores automatically\n",
    "processes = int(os.getenv('SLURM_CPUS_ON_NODE', mp.cpu_count()))\n",
    "print(f'Using {processes} cores.')\n",
    "\n",
    "# multiplier * processes particles are used in the PSO\n",
    "multiplier = 10\n",
    "popsize = multiplier*processes\n",
    "\n",
    "# Maximum number of PSO iterations\n",
    "maxiter = 2\n",
    "\n",
    "# Offset needed to deal with zeros in data in a Poisson distribution-based calibration. 1 suffices.\n",
    "poisson_offset = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1963897",
   "metadata": {},
   "source": [
    "## Data set to calibrate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671962c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:14.752400Z",
     "start_time": "2021-10-06T11:55:14.660646Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine the boundaries between which we will calibrate the model\n",
    "# Choose first date. Inspect df_sciensano.reset_index().DATE[0] if needed\n",
    "start_calibration = '2020-03-02'\n",
    "# Choose final date at which no interventions were felt (before first inflection point)\n",
    "end_calibration = '2020-03-21'\n",
    "\n",
    "# Identify the data. The fact that this is spatially explicit is handled automatically\n",
    "data=[df_sciensano[start_calibration:end_calibration]]\n",
    "\n",
    "# Only use the hospitalisation time series\n",
    "states = [\"H_in\"]\n",
    "\n",
    "# We use only one time series, so its weight is unity\n",
    "weights = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094fcef4",
   "metadata": {},
   "source": [
    "## PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ad25b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:51.432233Z",
     "start_time": "2021-10-06T11:55:14.754394Z"
    }
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "## WARNING HEAVY CALCULATION ##\n",
    "###############################\n",
    "\n",
    "# Define the free parameters. Only warmup and the (three) transmission coefficients have an effect.\n",
    "pars = ['warmup','beta_R', 'beta_U', 'beta_M']\n",
    "\n",
    "# Define the boundaries of the parameters defined above\n",
    "bounds=((0.0,60.0),(0.005,0.060), (0.005,0.060), (0.005,0.060))\n",
    "\n",
    "# Print the conditions for user feedback\n",
    "print('\\n------------------------------------------')\n",
    "print('PERFORMING CALIBRATION OF WARMUP and BETAs')\n",
    "print('------------------------------------------\\n')\n",
    "print('Using data from '+start_calibration+' until '+end_calibration+'\\n')\n",
    "print('1) Particle swarm optimization')\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n')\n",
    "print(f'Using {str(processes)} cores for a population of {popsize}, for maximally {maxiter} iterations.\\n')\n",
    "\n",
    "# run optimisation and safe the result in vector theta_first\n",
    "theta = pso.fit_pso(model, data, pars, states, bounds, weights=weights, maxiter=maxiter, popsize=popsize, dist='poisson',\n",
    "                    poisson_offset=poisson_offset, agg=agg, start_date=start_calibration, processes=processes)\n",
    "\n",
    "# Print statement to stdout once\n",
    "print(f'\\nPSO RESULTS:')\n",
    "print(f'------------')\n",
    "print(f'warmup: {theta[0]}')\n",
    "print(f'infectivities {pars[1:4]}: {theta[1:]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ea1de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:55:52.080909Z",
     "start_time": "2021-10-06T11:55:51.433231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign estimate of the transmission coefficients to the model with a utils function\n",
    "warmup, pars_PSO = assign_PSO(model.parameters, pars, theta)\n",
    "warmup = round(warmup)\n",
    "model.parameters = pars_PSO\n",
    "\n",
    "# Perform simulation with best-fit results\n",
    "out = model.sim(end_calibration,start_date=start_calibration,warmup=warmup)\n",
    "\n",
    "# SANITY CHECK: plot output of the calibration on the ascending part of the first wave for *national* data and simulation\n",
    "fig,ax=plt.subplots(figsize=(16,4))\n",
    "ax.grid(False)\n",
    "graph=out['H_in'].sum(dim='Nc').sum(dim='place').plot(ax=ax)\n",
    "# NOTE: the scatter plot below is very ugly. There is a better way to do this, but I can't be bothered now\n",
    "graph=ax.scatter(df_sciensano.sum(axis=1).reset_index()['DATE'].values,df_sciensano.sum(axis=1).reset_index()[0].values, color='k', s=1)\n",
    "\n",
    "# Print warmup value for user reference\n",
    "message=f'Warmup value: {warmup} days.'\n",
    "print('='*len(message))\n",
    "print(message)\n",
    "print('='*len(message))\n",
    "\n",
    "# Note that PSO suffices for the search for warmup value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d22225",
   "metadata": {},
   "source": [
    "# Calibration of the _entire_ pandemic\n",
    "\n",
    "Note that this begins with the same procedure as for the PSO, but with more parameters.\n",
    "\n",
    "@TIJS: this appears to malfunction when processes is not 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d7160",
   "metadata": {},
   "source": [
    "## Technical setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da93461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:58:53.112067Z",
     "start_time": "2021-10-06T11:58:53.029249Z"
    }
   },
   "outputs": [],
   "source": [
    "### PSO settings\n",
    "\n",
    "# Hard-code number of cores used\n",
    "processes = 5# 1\n",
    "# Find number of available cores automatically\n",
    "# processes = int(os.getenv('SLURM_CPUS_ON_NODE', mp.cpu_count()))\n",
    "print(f'Using {processes} cores.')\n",
    "\n",
    "# multiplier * processes particles are used in the PSO\n",
    "multiplier = 1 # 10\n",
    "popsize = multiplier*processes\n",
    "\n",
    "# Maximum number of PSO iterations\n",
    "maxiter = 2\n",
    "\n",
    "\n",
    "### MCMC settings\n",
    "\n",
    "# Disable backend. Still not sure what this does\n",
    "backend=None\n",
    "\n",
    "# Maximum number of PSO iterations\n",
    "max_n = 100 # 10 # 1000\n",
    "\n",
    "# Print result every {print_n} steps. Only relevant when no progress bar can be shown (as on HPC)\n",
    "print_n = 10\n",
    "\n",
    "# Offset needed to deal with zeros in data in a Poisson distribution-based calibration. 1 suffices.\n",
    "poisson_offset = 1\n",
    "\n",
    "# Define string that identifies the output\n",
    "spatial_unit = f'{agg}-full-pandemic'\n",
    "\n",
    "# Define date at which the calibration is initiated\n",
    "run_date = str(pd.to_datetime('today').date())\n",
    "\n",
    "# Define job. This is an artefact in run_MCMC that distinguishes between a full run or a R0 run,\n",
    "# which in turn defines the name of the saved .npy file\n",
    "job = 'FULL'\n",
    "\n",
    "# Choose output. In a Notebook (rather than a script), output is given regardless\n",
    "progress = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bead0fa",
   "metadata": {},
   "source": [
    "## Data set to calibrate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ee8e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:56:52.308728Z",
     "start_time": "2021-10-06T11:56:52.224702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine the boundaries between which we will calibrate the model\n",
    "# Choose first date. Inspect df_sciensano.head() if needed\n",
    "start_calibration = '2020-03-02'\n",
    "# Choose first date. Inspect df_sciensano.tail() if needed\n",
    "end_calibration = '2020-08-27' # '2021-08-27'\n",
    "\n",
    "# Identify the data. The fact that this is spatially explicit is handled automatically\n",
    "data=[df_sciensano[start_calibration:end_calibration]]\n",
    "\n",
    "# Only use the hospitalisation time series\n",
    "states = [\"H_in\"]\n",
    "\n",
    "# We use only one time series, so its weight is unity\n",
    "weights = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dbf33a",
   "metadata": {},
   "source": [
    "## PSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06339d",
   "metadata": {},
   "source": [
    "Which of the 14 parameters can be fixed?\n",
    "- Seasonality: `amplitude`: 30 (approx) `peak_shift`: 21 days (approx)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd39615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:56:55.527894Z",
     "start_time": "2021-10-06T11:56:55.448109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the 14 free parameters. Now there are many more that all have effects.\n",
    "\n",
    "# transmission\n",
    "pars1 = ['beta_R',     'beta_U',      'beta_M']\n",
    "bounds1=((0.005,0.060),(0.005,0.060), (0.005,0.060))\n",
    "\n",
    "# Social intertia\n",
    "pars2 = ['l1',   'l2']\n",
    "bounds2=((4,14), (4,14))\n",
    "\n",
    "# Prevention parameters (effectivities)\n",
    "pars3 = ['prev_schools', 'prev_work', 'prev_rest_lockdown', 'prev_rest_relaxation', 'prev_home']\n",
    "bounds3=((0.15,0.95),    (0.05,0.95), (0.05,0.95),          (0.05,0.95),            (0.05,0.95))\n",
    "\n",
    "# Effect of VOCs\n",
    "pars4 = ['K_inf1',  'K_inf2']\n",
    "bounds4=((1.4,1.6), (2.1,2.4))\n",
    "\n",
    "# Effect of seasonality\n",
    "pars5 = ['amplitude', 'peak_shift']\n",
    "bounds5=((0,0.30),    (-31, 31))\n",
    "\n",
    "# Join them together\n",
    "pars = pars1 + pars2 + pars3 + pars4 + pars5\n",
    "bounds = bounds1 + bounds2 + bounds3 + bounds4 + bounds5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c77584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:57:08.268755Z",
     "start_time": "2021-10-06T11:56:55.820143Z"
    }
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "## WARNING HEAVY CALCULATION ##\n",
    "###############################\n",
    "\n",
    "# Print the conditions for user feedback\n",
    "print('\\n------------------------------------------')\n",
    "print('PERFORMING CALIBRATION OF WARMUP and BETAs')\n",
    "print('------------------------------------------\\n')\n",
    "print('Using data from '+start_calibration+' until '+end_calibration+'\\n')\n",
    "print('1) Particle swarm optimization')\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n')\n",
    "print(f'Using {str(processes)} cores for a population of {popsize}, for maximally {maxiter} iterations.\\n')\n",
    "\n",
    "# run optimisation and safe the result in vector theta_first. Note how now the parameter warmup=warmup was added.\n",
    "theta = pso.fit_pso(model, data, pars, states, bounds, weights=weights, maxiter=maxiter, popsize=popsize, dist='poisson',\n",
    "                    poisson_offset=poisson_offset, agg=agg, start_date=start_calibration, processes=processes, warmup=warmup)\n",
    "\n",
    "# Print statement to stdout once\n",
    "print(f'\\nPSO RESULTS:')\n",
    "print(f'------------')\n",
    "print(f'infectivities {pars[0:3]}: {theta[0:3]}.')\n",
    "print(f'social intertia {pars[3:5]}: {theta[3:5]}.')\n",
    "print(f'prevention parameters {pars[5:10]}: {theta[5:10]}.')\n",
    "print(f'VOC effects {pars[10:12]}: {theta[10:12]}.')\n",
    "print(f'Seasonality {pars[12:]}: {theta[12:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a13732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:57:43.336969Z",
     "start_time": "2021-10-06T11:57:41.333034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign estimate of the transmission coefficients to the model with a utils function\n",
    "pars_PSO = assign_PSO(model.parameters, pars, theta)\n",
    "model.parameters = pars_PSO\n",
    "\n",
    "# Perform simulation with best-fit results\n",
    "out = model.sim(end_calibration,start_date=start_calibration,warmup=warmup)\n",
    "\n",
    "# SANITY CHECK: plot output of the calibration on the ascending part of the first wave for *national* data and simulation\n",
    "fig,ax=plt.subplots(figsize=(16,4))\n",
    "ax.grid(False)\n",
    "graph=out['H_in'].sum(dim='Nc').sum(dim='place').plot(ax=ax)\n",
    "# NOTE: the scatter plot below is very ugly. There is a better way to do this, but I can't be bothered now\n",
    "graph=ax.scatter(df_sciensano.sum(axis=1).reset_index()['DATE'].values,df_sciensano.sum(axis=1).reset_index()[0].values, color='k', s=1)\n",
    "\n",
    "# Print warmup value for user reference\n",
    "message=f'Warmup value: {warmup} days.'\n",
    "print('='*len(message))\n",
    "print(message)\n",
    "print('='*len(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17293c69",
   "metadata": {},
   "source": [
    "## MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c2aa04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:59:02.203197Z",
     "start_time": "2021-10-06T11:59:02.115942Z"
    }
   },
   "outputs": [],
   "source": [
    "# overwrite number of cores used. Multiprocessing does appear to work for MCMC\n",
    "processes = 5 # 2\n",
    "# processes = int(os.getenv('SLURM_CPUS_ON_NODE', mp.cpu_count()))\n",
    "\n",
    "# Redefine theta if necessary (in case of a disrupted session)\n",
    "# theta = [ 3.17718733e-02,  2.57464336e-02,  3.10234015e-02,  1.10146871e+01, \\\n",
    "#           9.77557891e+00,  3.52930023e-01,  5.00000000e-02,  5.00000000e-02, \\\n",
    "#           4.51681887e-01,  6.69250082e-01,  1.60000000e+00,  2.12120593e+00, \\\n",
    "#           4.12019815e-02, -3.10000000e+01]\n",
    "# warmup = 37\n",
    "\n",
    "# Define simple uniform priors based on the PSO bounds\n",
    "log_prior_fcn = [prior_uniform, prior_uniform, prior_uniform, prior_uniform, \\\n",
    "                 prior_uniform, prior_uniform, prior_uniform, prior_uniform, \\\n",
    "                 prior_uniform, prior_uniform, prior_uniform, prior_uniform, \\\n",
    "                 prior_uniform, prior_uniform]\n",
    "log_prior_fcn_args = bounds\n",
    "\n",
    "# Perturbate PSO estimate by a certain maximal *fraction* in order to start every chain with a different initial condition\n",
    "# Generally, the less certain we are of a value, the higher the perturbation fraction\n",
    "# pars1 = ['beta_R',     'beta_U',      'beta_M']\n",
    "pert1=[0.02, 0.02, 0.02]\n",
    "\n",
    "# pars2 = ['l1',   'l2']\n",
    "pert2=[0.05, 0.05]\n",
    "\n",
    "# pars3 = ['prev_schools', 'prev_work', 'prev_rest_lockdown', 'prev_rest_relaxation', 'prev_home']\n",
    "pert3=[0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "# pars4 = ['K_inf1',  'K_inf2']\n",
    "pert4=[0.1, 0.1]\n",
    "\n",
    "# pars5 = ['amplitude', 'peak_shift']\n",
    "pert5=[0.2, 0.2]\n",
    "\n",
    "# Join them together\n",
    "pert = pert1 + pert2 + pert3 + pert4 + pert5\n",
    "\n",
    "# Extract the number of dimensions, number of walkers, and all initial positions of all walkers\n",
    "ndim, nwalkers, pos = perturbate_PSO(theta, pert, multiplier=processes, bounds=log_prior_fcn_args, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f263447",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T11:59:02.932159Z",
     "start_time": "2021-10-06T11:59:02.849997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the sampler backend if needed\n",
    "if backend:\n",
    "    filename = f'{spatial_unit}_backend_{run_date}'\n",
    "    backend = emcee.backends.HDFBackend(results_folder+filename)\n",
    "    backend.reset(nwalkers, ndim)\n",
    "\n",
    "# Labels for traceplots\n",
    "labels = ['$\\\\beta_R$', '$\\\\beta_U$', '$\\\\beta_M$', \\\n",
    "          '$l_1$', '$l_2$', \\\n",
    "          '$\\\\omega_{schools}$', '$\\\\omega_{work}$', '$\\\\omega_{rest,lock}$', '$\\\\omega_{rest,rel}$', '$\\\\omega_{home}$', \\\n",
    "          '$K_{inf,1}$', '$K_{inf,2}$', 'amplitude', 'peak shift']\n",
    "\n",
    "# Arguments of chosen objective function\n",
    "objective_fcn = objective_fcns.log_probability\n",
    "objective_fcn_args = (model, log_prior_fcn, log_prior_fcn_args, data, states, pars)\n",
    "objective_fcn_kwargs = {'weights':weights, 'draw_fcn':None, 'samples':{}, 'start_date':start_calibration, \\\n",
    "                        'warmup':warmup, 'dist':'poisson', 'poisson_offset':poisson_offset, 'agg':agg}\n",
    "\n",
    "\n",
    "print('\\n2) Markov-Chain Monte-Carlo sampling')\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n')\n",
    "print(f'Using {processes} cores for {ndim} parameters, in {nwalkers} chains.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e352c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T12:17:30.097180Z",
     "start_time": "2021-10-06T11:59:25.852513Z"
    }
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "## WARNING HEAVY CALCULATION ##\n",
    "###############################\n",
    "\n",
    "# Run MCMC sampler\n",
    "# Print autocorrelation and traceplot every print_n'th iteration\n",
    "sampler = run_MCMC(pos, max_n, print_n, labels, objective_fcn, objective_fcn_args, \\\n",
    "                   objective_fcn_kwargs, backend, spatial_unit, run_date, job, progress=True, agg=agg)\n",
    "\n",
    "# Note: with 2 cores at work, the MCMC achieves a speed of roughly 20 iterations per second.\n",
    "# Also note that this calculation automatically stops working after a while, as if it keeps on building up elements\n",
    "# To store in its memory ...?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf93c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:46:23.479101Z",
     "start_time": "2021-09-17T09:46:23.366062Z"
    }
   },
   "source": [
    "# Process and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results from the MCMC need to be thinned, and the first {discard} values need to be discarded.\n",
    "\n",
    "# Choose a default thinning of 1\n",
    "thin = 1\n",
    "try:\n",
    "    # We want a sample from every uncorrelated 'block' of data, which we define as 50 times the autocorrelation time\n",
    "    autocorr = sampler.get_autocorr_time()\n",
    "    thin = max(1,int(0.5 * np.min(autocorr)))\n",
    "    print(f'Convergence: the chain is longer than 50 times the intergrated autocorrelation time.\\nPreparing to save samples with thinning value {thin}.')\n",
    "    sys.stdout.flush()\n",
    "except:\n",
    "    print('Warning: The chain is shorter than 50 times the integrated autocorrelation time.\\nUse this estimate with caution and run a longer chain! Saving all samples (thinning=1).\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# Choose a default discard value of 0 (no discard)\n",
    "discard=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is useful on the HPC\n",
    "\n",
    "# # Print runtime in hours\n",
    "# final_time = datetime.datetime.now()\n",
    "# runtime = (final_time - intermediate_time)\n",
    "# totalMinute, second = divmod(runtime.seconds, 60)\n",
    "# hour, minute = divmod(totalMinute, 60)\n",
    "# day = runtime.days\n",
    "# if day == 0:\n",
    "#     print(f\"Run time MCMC: {hour}h{minute:02}m{second:02}s\")\n",
    "# else:\n",
    "#     print(f\"Run time MCMC: {day}d{hour}h{minute:02}m{second:02}s\")\n",
    "# sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update and save samples dictionary for all parameters in the MCMC sampler\n",
    "flat_samples = sampler.get_chain(discard=discard,thin=thin,flat=True)\n",
    "samples_dict = {}\n",
    "for count,name in enumerate(pars):\n",
    "    samples_dict[name] = flat_samples[:,count].tolist()\n",
    "\n",
    "# Add information on warmup, calibration window, and MCMC walkers    \n",
    "samples_dict.update({\n",
    "    'warmup' : warmup,\n",
    "    'start_date' : start_calibration,\n",
    "    'end_date' : end_calibration,\n",
    "    'n_chains': int(nwalkers)\n",
    "})\n",
    "\n",
    "# Define location and name of the saved JSON file\n",
    "samples_path = f\"../../data/interim/model_parameters/COVID19_SEIRD/calibrations/{agg}/\"\n",
    "json_name = f\"{spatial_unit}_{run_date}.json\"\n",
    "json_file = samples_path + json_name\n",
    "\n",
    "# Actually save it there\n",
    "with open(json_file, 'w') as fp:\n",
    "    json.dump(samples_dict, fp)\n",
    "\n",
    "print('DONE!')\n",
    "print(f'SAMPLES DICTIONARY SAVED IN \"{json_file}\"')\n",
    "print('-----------------------------------------------------------------------------------------------------------------------------------\\n')\n",
    "# sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
