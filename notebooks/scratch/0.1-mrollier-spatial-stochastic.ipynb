{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial model\n",
    "\n",
    "**Open questions**\n",
    "* When `age_stratified=False`, some important parameters (such as `h`) are not loaded (or at least that's what the function information says). This is wrong?\n",
    "    * Pretty sure this is wrong and also sure this should be fixed\n",
    "* Why are the matrices found by `polymod.get_interaction_matrices()` not identical to those found in the [SOCRATES](https://lwillem.shinyapps.io/socrates_rshiny/) tool? How is this tool to be interpreted? See [this](https://www.medrxiv.org/content/10.1101/2020.03.03.20030627v2) paper.\n",
    "* When taking the parameter values with `get_COVID19_SEIRD_parameters(age_stratified=True)`, not all values are being copied from their age-stratified values. Examples:\n",
    "    * Mortalities for patients in ICU *is* age-stratified\n",
    "    * Average number of days in cohort when patient will recover *is not* age-stratified. Why not? Because there is not enough data available.\n",
    "* Should we work with the most recent data where possible? E.g. for initial population, almost all arrondissements have higher population now than 9 years ago (2011 census), and this is easily found online.\n",
    "* Why is the initial population per age in `polymod.get_interaction_matrices()[0]` significantly larger than the sum over all arrondissements in `../../data/interim/census_2011/initN.csv`? Which one should we use? Both are from roughly the same time period, no?\n",
    "    * Compare e.g. `polymod.get_interaction_matrices()[0]` with `initN_df['[0,10['].sum()`\n",
    "* In the relative susceptibility taken from the study of Davies, *all* $s$-values are below 1. I would expect the age-weighed average of $s$ to be precisely 1.\n",
    "    * Why is this not the case?\n",
    "    * Does that mean that we must not take `pars_dict['s'] = 1` in the case of no age stratification?\n",
    "    * I have written down these concerns in a $\\LaTeX$ document\n",
    "* `pars_dict['Nc'] = np.array([11.2])` comes from the average number of contacts, weighed by age. The other matrices do *not* appear to be weighed by age. What do we want?\n",
    "    * This is also updated to the correct value in SOCRATES (18 point something)\n",
    "* The simulation sometimes runs into a division by zero (but generally continues running)\n",
    "* What does the `.sim` attribute do? I cannot find this anywhere.\n",
    "    * See `base.py`\n",
    "* I do not understand how the `integrate` function defined in `models.py` is related to the rest of the code, and I also do not understand how `BaseModel` can be an argument of the class in `models.py`. Confusing.\n",
    "    * Update: `integrate` is part of `base.py`. The search function only works for the part of the code you can see!\n",
    "* Why, in `models.py`, is there a difference between `parameters_stratified_names` and `stratification`? Not very clear\n",
    "    * One is used simply to sum up the stratified parameters. The second one does so too, but is also used to determine the dimensions all the stratifications are supposed to have. They are the mobility matrix and the overall contact matrix.\n",
    "* Shouldn't `Nc` be symmetric? Right now it isn't, and this causes some ambiguity in the calculation of the probability of infection P\n",
    "    * Tijs has made a lot of improvements on this since last meeting\n",
    "* What are the classes `H_in`, `H_out` and `H_tot`?\n",
    "    * These are parameters that do not belong to SEIR compartments, but are very useful to plot. Therefore they are calculated from the propensities in the end.\n",
    "* If I take `1e20` (impossibly many) infected people, there is still only a chance of 20 percent that a baby will become exposed the next day. Is this logical? Is this perhaps what the normalisation establishes?\n",
    "\n",
    "**Open tasks**\n",
    "* Go through the structure of all `data` and `src` modules, in particular `BaseModel`\n",
    "* Adjust `get_COVID19_SEIRD_parameters` to take and return data needed for spatial extension\n",
    "    * It would be nice to be able to *choose* the level of stratification\n",
    "        * Age: take data straight from the full SOCRATES tool (probably not very convenient to implement)\n",
    "        * Space: choose between *artificial*, *postal code*, municipality, arrondissement, province. Focus is on provinces, because this is what will be used in the FAGG\n",
    "    * Adjust the function description (this is kind of a mess now)\n",
    "* Find a way to *first* work *without* age stratification\n",
    "    * Make a clear distinction between age-stratified case and non-stratified case\n",
    "    * Make available all non-stratified data, and make sure this is correct: currently the average $m_0$ is set to 0.5, which seems terribly high\n",
    "* Show scatter plot to demonstrate 'Matthew effect'\n",
    "* Change the implementations in `models.py` into nice `matmul` methods\n",
    "    * I have done quite the opposite: in its current implementation, it is very clear what is going on (\"naive\" Python), but it is not very elegant. Naturally, this does not have priority.\n",
    "* Interpret the `Effective-infection-probability_arr.jpg` image. This does *not* look very realistic!\n",
    "* Add `spatial='test'` as an option, which demonstrates only the arrondissements Brussel, Antwerpen and Gent and only takes into account an artificial mobility between these three\n",
    "* Implement the possibility of making a model without age stratification but with spatial stratification\n",
    "* Find an elegant way to choose the spatial stratification in `coordinates = [read_coordinates_nis(spatial='arr')]` in `models.py` **priority**\n",
    "* Implement Age-stratification for mobility\n",
    "    * Not urgent because there is no such data available yet\n",
    "* fill up these missing values in the hospital data and update the existing values with newer data from new studies. If this does not exist, we may have to come back to the averages, but this is not very representative\n",
    "* Find better population data that is both very recent (like `/demographic/BELagedist_10year.txt`) and spatially stratified (like `interim/demographic/initN_xxx.csv`)\n",
    "    * Not entirely urgent: they only differ 50k total people\n",
    "    * The former data is from 2019, the latter is from 2018\n",
    "    * The current total Belgian population ([see here](worldometers.info/world-population/belgium-population/)) is 11 603 334 people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T14:54:43.971177Z",
     "start_time": "2020-10-07T14:54:42.436998Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import corner # make beautiful corner plots for demonstrating the parameter distributions\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import datetime\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.dates as mdates # sophisticated date plotting capabilities\n",
    "import math\n",
    "import xarray as xr # labels in the form of dimensions, coordinates and attributes\n",
    "import emcee # Goodman & Weareâ€™s Affine Invariant Markov chain Monte Carlo (**MCMC**) Ensemble sampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from covid19model.optimization import objective_fcns\n",
    "from covid19model.models import models\n",
    "from covid19model.models.utils import name2nis, read_coordinates_nis, read_areas, read_pops, dens_dep # New function that translates names to NIS codes\n",
    "from covid19model.data import google, sciensano, model_parameters\n",
    "from covid19model.visualization.output import population_status, infected\n",
    "from covid19model.visualization.optimization import plot_fit, traceplot\n",
    "\n",
    "# OPTIONAL: Load the \"autoreload\" extension so that package code can change\n",
    "%load_ext autoreload\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "# This may be useful because the `covid19model` package is under construction\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Understand current code and data loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `COVID19_SEIRD_sto_spatial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The class `COVID19_SEIRD_sto_spatial` inside `models.py` in which the integration happens, takes the same inputs as `BaseModel`. This is:\n",
    "1. `states`: dictionary of initial states of all (stratified) compartments. Typically, only the compartments S, E and T (total) are non-zero at the start. The states are matrices with dimensions of the stratification (e.g. 3x4)\n",
    "2. `parameters`: dictionary of parameters (both stratified and not) that are obtained with `parameters.get_COVID19_SEIRD_parameters()`\n",
    "3. `compliance`. Set to `None` by default, but we will generally use `ramp_2`\n",
    "4. `discrete`. Set to `False` by default, but we implement a discrete set now (i.e. `True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.252090Z",
     "start_time": "2020-10-07T10:35:30.167017Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/interim/census_2011/census-2011-updated_row-commutes-to-column_arrondissements.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-5a748a02d932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Read as: fraction of (row) commutes to (column), so the sum of every row should be unity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmobility_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../data/interim/census_2011/census-2011-updated_row-commutes-to-column_arrondissements.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NIS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mNIS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmobility_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Normalize recurrent mobility matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/interim/census_2011/census-2011-updated_row-commutes-to-column_arrondissements.csv'"
     ]
    }
   ],
   "source": [
    "# When spatial==True, the mobility matrix is added to the parameter dictionary:\n",
    "# This is only the 43x43 matrix, and contains the old definitions of arrondissements (does not have 58000 yet)\n",
    "# Read as: fraction of (row) commutes to (column), so the sum of every row should be unity\n",
    "\n",
    "mobility_df=pd.read_csv('../../data/interim/census_2011/census-2011-updated_row-commutes-to-column_arrondissements.csv', index_col=['NIS'])\n",
    "NIS=mobility_df.values.astype(float)\n",
    "# Normalize recurrent mobility matrix\n",
    "for i in range(NIS.shape[0]):\n",
    "    NIS[i,:]=NIS[i,:]/sum(NIS[i,:])\n",
    "NIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.254040Z",
     "start_time": "2020-10-07T10:35:30.100Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Every arrondissement has an initial population (initial number of susceptibles) per age group\n",
    "\n",
    "# Read CSV as dataframe with the first column (NIS) as index\n",
    "NIS = read_coordinates_nis(name='arrond')\n",
    "\n",
    "# Save the population distribution for all arrondissements\n",
    "NIS\n",
    "\n",
    "# Make sure the shape of the initN is 1x43 rather than just 43\n",
    "# N_dummy = []\n",
    "# for i in range(len(initN)):\n",
    "#     N_dummy.append([initN[i]])\n",
    "    \n",
    "# initN = np.asarray(N_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `get_COVID19_SEIRD_parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The Python code `data/model_parameters.py` contains the important (and only) function `get_COVID19_SEIRD_parameters` which fetches all necessary parameters. Information (note that this is quite a mess):\n",
    "* Takes two inputs\n",
    "    * `stratified`: Boolean, choose whether or not there is age stratification\n",
    "    * `spatial`: Boolean, choose whether or not there is spatial stratification\n",
    "* Returns the parameter dictionary, as desired as input to `COVID19_SEIRD_sto_spatial(BaseModel)`\n",
    "* If both `stratified` and `spatial` are true, the parameters are ...\n",
    "    * `beta` : probability $\\beta$ of infection when encountering an infected person\n",
    "    * `sigma` : length $\\sigma$ of the latent period\n",
    "    * `omega` : length $\\omega$ of the pre-symptomatic infectious period\n",
    "    * `zeta`: effect $\\zeta$ of re-susceptibility and seasonality\n",
    "    * `a` : probability $a$ of an asymptomatic cases\n",
    "    * `m` : probability $m$ of an initially mild infection (m=1-a): superfluous\n",
    "    * `da` : duration $d_a$ of the infection in case of asymptomatic\n",
    "    * `dm` : duration $d_m$ of the infection in case of mild\n",
    "    * `der` : duration of stay $d_{\\text{ER}}$ in emergency room/buffer ward\n",
    "    * `dc` : average length $d_c$ of a hospital stay when not in ICU\n",
    "    * `dICU_R` : average length $d_{\\text{ICU},R}$ of a hospital stay in ICU in case of recovery\n",
    "    * `dICU_D`: average length $d_{\\text{ICU},D}$ of a hospital stay in ICU in case of death\n",
    "    * `dhospital` : time $d_\\text{hosp}$ before a patient reaches the hospital (*below: age-stratified*)\n",
    "    * `s`: relative susceptibilities $s_i$ to infection (unique)\n",
    "    * `a` : probabilities $a_i$ of an asymptomatic case (overwrites $a$ and $m$)\n",
    "    * `h` : probabilities $h_i$ of hospitalisation for a mild infection\n",
    "    * `c` : probabilities $c_i$ of hospitalisation in Cohort (non-ICU)\n",
    "    * `m_C` : mortalities $m_{C,i}$ in Cohort\n",
    "    * `m_ICU` : mortalities $m_{\\text{ICU},i}$ in ICU (*below: spatially stratified*)\n",
    "    * `NIS`: normalised mobility between NIS codes\n",
    "* If no age stratification is chosen, the final value in the data column always communicates the weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.255038Z",
     "start_time": "2020-10-07T10:35:30.102Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Most hospital data is taken from `data/interim/model_parameters/AZMM_UZG_hospital_parameters.csv`,\n",
    "# which is good but may be updated with Sciensano data at some point.\n",
    "# Question: why is m_C age-stratified ([:-1]) and e.g. dC_R not ([-1])?\n",
    "\n",
    "# This hospital data looks as follows\n",
    "df = pd.read_csv('../../data/interim/model_parameters/AZMM_UZG_hospital_parameters.csv', sep=',',header='infer')\n",
    "df = df.fillna(0)\n",
    "print(df)\n",
    "\n",
    "m_ICU = np.array(df['m0_{ICU}'].values[:-1])\n",
    "dc_R = np.array(df['dC_R'].values[-1])\n",
    "\n",
    "print(m_ICU)\n",
    "print(dc_R)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.256035Z",
     "start_time": "2020-10-07T10:35:30.104Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Some additional data is taken from `verity_etal.csv` and `davies_etal.csv` in the raw directory\n",
    "# full Verity data\n",
    "df = pd.read_csv('../../data/raw/model_parameters/verity_etal.csv', sep=',',header='infer')\n",
    "print(df)\n",
    "\n",
    "# h: probability of being hospitalised per age\n",
    "h = np.array(df.loc[:,'symptomatic_hospitalized'].astype(float).tolist())/100\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.257032Z",
     "start_time": "2020-10-07T10:35:30.105Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# full Davies data\n",
    "df_asymp = pd.read_csv('../../data/raw/model_parameters/davies_etal.csv', sep=',',header='infer')\n",
    "print(df_asymp)\n",
    "\n",
    "# a: probabilty of being asymptomatic per age; s: relative susceptibility per age\n",
    "a = np.array(df_asymp.loc[:,'fraction asymptomatic'].astype(float).tolist())\n",
    "s = np.array(df_asymp.loc[:,'relative susceptibility'].astype(float).tolist())\n",
    "print(a)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.258030Z",
     "start_time": "2020-10-07T10:35:30.106Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# If there is no age stratification (as we may want to try at first in the simplified spatial model),\n",
    "# the parameter dictionary takes parameter values from `../../data/raw/model_parameters/non_stratified.csv`\n",
    "# and updates the parameters dictionary with these\n",
    "\n",
    "non_strat = pd.read_csv(\"../../data/raw/model_parameters/non_stratified.csv\", sep=',',header='infer')\n",
    "a = non_strat['a'].values[0]\n",
    "a\n",
    "non_strat\n",
    "# pars_dict.update({key: np.array(value) for key, value in non_strat.to_dict(orient='list').items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.259027Z",
     "start_time": "2020-10-07T10:35:30.108Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Beta is set manually\n",
    "beta = 0.03492\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.260024Z",
     "start_time": "2020-10-07T10:35:30.109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remaining parameters\n",
    "\n",
    "df_other_pars = pd.read_csv('../../data/raw/model_parameters/others.csv', sep=',',header='infer')\n",
    "df_other_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `polymod.get_interaction_matrices`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This function returns the total number of individuals in ten year age bins in the Belgian population and the interaction matrices Nc at home, at work, in schools, on public transport, during leisure activities and during other activities. This is eventually linked to Lander Willem's SOCRATES tool, saved as `txt` files in `../../data/raw/polymod/interaction_matrices/Belgium/`.\n",
    "\n",
    "Returns ...\n",
    "1. `initN` : np.array : number of Belgian individuals, regardless of sex, in ten year age bins. **`initN[0]` refers to the youngest (0-10 years)**\n",
    "2. `Nc_home` :  np.array (9x9) : number of daily contacts at home of individuals in age group X with individuals in age group Y\n",
    "3. `Nc_work` :  np.array (9x9) : number of daily contacts in the workplace of individuals in age group X with individuals in age group Y\n",
    "4. `Nc_schools` :  np.array (9x9) : number of daily contacts in schools of individuals in age group X with individuals in age group Y\n",
    "5. `Nc_transport` :  np.array (9x9) : number of daily contacts on public transport of individuals in age group X with individuals in age group Y\n",
    "6. `Nc_leisure` :  np.array (9x9) : number of daily contacts during leisure activities of individuals in age group X with individuals in age group Y\n",
    "7. `Nc_others` :  np.array (9x9) : number of daily contacts in other places of individuals in age group X with individuals in age group Y\n",
    "8. `Nc_total` :  np.array (9x9) : total number of daily contacts of individuals in age group X with individuals in age group Y, calculated as the sum of all the above interaction. **`Nc_total[i][j]` is the number of visits that agent in age group `i` brings to agent in age group `j`**\n",
    "\n",
    "If no age stratification is chosen, `initN` is the total Belgian population, and `Nc_total` is the average number of contacts per day, fixed at 11.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.261023Z",
     "start_time": "2020-10-07T10:35:30.111Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Interaction matrix is taken from the Polymod study\n",
    "# Assign Nc_total from the Polymod study to the parameters dictionary\n",
    "# NOTE how this does not correspond to the data on the SOCRATES tool website.\n",
    "Nc_schools = polymod.get_interaction_matrices()[3]\n",
    "pd.DataFrame(Nc_schools)\n",
    "\n",
    "pd.DataFrame(polymod.get_interaction_matrices()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Initialise and execute model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Messing around with new `time_dependent_parameters` implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.263016Z",
     "start_time": "2020-10-07T10:35:30.112Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "initN, Nc_home, Nc_work, Nc_schools, Nc_transport, Nc_leisure, Nc_others, Nc_total = polymod.get_interaction_matrices()\n",
    "levels = initN.size\n",
    "\n",
    "# ramp_2 with new time_dependent_parameters definitions\n",
    "# param currently unused\n",
    "def social_policy_func(t,param,policy_time,policy1,policy2,l,tau):\n",
    "    if t < policy_time:\n",
    "        return policy1\n",
    "    else:\n",
    "        return policy1 + (1/l)*(t-policy_time)*(policy2-policy1)\n",
    "    \n",
    "# Load the parameters using `get_COVID19_SEIRD_parameters()`.\n",
    "params = model_parameters.get_COVID19_SEIRD_parameters()\n",
    "\n",
    "# Add the delayed ramp parameters and the social_policy_func parameters to the parameter dictionary.\n",
    "params.update({'l': 1,\n",
    "              'tau': 5})\n",
    "params.update({'policy1': Nc_total, # No restrictions\n",
    "          'policy2': Nc_home, # Everyone in home isolation\n",
    "          'policy_time': 40})\n",
    "\n",
    "# Define the initial condition: one exposed inidividual in every age category\n",
    "initial_states = {'S': initN, 'E': np.ones(levels)}\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = models.COVID19_SEIRD_sto(initial_states, params, time_dependent_parameters={'Nc': social_policy_func})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Define initial states and (compliance) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.263016Z",
     "start_time": "2020-10-07T10:35:30.114Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the parameters using `get_COVID19_SEIRD_parameters()`\n",
    "params = model_parameters.get_COVID19_SEIRD_parameters(age_stratified=True, spatial=True)\n",
    "\n",
    "def social_policy_func(t,param,policy_time,policy1,policy2,l,tau):\n",
    "    if t < policy_time:\n",
    "        return policy1\n",
    "    else:\n",
    "        return policy1 + (1/l)*(t-policy_time)*(policy2-policy1)\n",
    "    \n",
    "# Load the parameters using `get_COVID19_SEIRD_parameters()`.\n",
    "params = model_parameters.get_COVID19_SEIRD_parameters()\n",
    "\n",
    "# Add the delayed ramp parameters and the social_policy_func parameters to the parameter dictionary.\n",
    "params.update({'l': 1,\n",
    "              'tau': 5})\n",
    "params.update({'policy1': Nc_total, # No restrictions\n",
    "          'policy2': Nc_home, # Everyone in home isolation\n",
    "          'policy_time': 40})\n",
    "\n",
    "# Define a cluster of 20 infectees in one or two arrondissements\n",
    "\n",
    "# Define an empty matrix with the dimensions of an exposed age-stratified population per arrondissement (1x43)\n",
    "E = np.zeros(initN.shape)\n",
    "\n",
    "print(initN)\n",
    "\n",
    "# If the index value in the initN dataframe corresponds to the NIS code of (arrondissement), fill the entire row with (value)\n",
    "# `numpy.where(condition[, x, y])`: Return elements chosen from x or y depending on condition.\n",
    "E[np.where(NIS==name2nis('arrondissement ieper'))[0][0]] = 20 \n",
    "E[np.where(NIS==name2nis('arrondissement tongeren'))[0][0]] = 20\n",
    "\n",
    "# Define the initial condition: two exposed inidividual in every age category of two arrondissements\n",
    "# The rest of the categories are empty by default\n",
    "initial_states = {'S': initN, 'E': E}\n",
    "\n",
    "# Load the compliance model (we use ramp_2, which I guess is the time-delayed ramp)\n",
    "from covid19model.models.compliance import ramp_2\n",
    "\n",
    "# Initialize the discrete model with ramp_2 compliance, parameters for the spatial case, and initial conditions (S and E population)\n",
    "model = models.COVID19_SEIRD_sto(initial_states, params, time_dependent_parameters=ramp_2, discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.264014Z",
     "start_time": "2020-10-07T10:35:30.115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.266010Z",
     "start_time": "2020-10-07T10:35:30.117Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Change beta value\n",
    "# Original value is 0.03492\n",
    "model.parameters['beta'] = 0.5\n",
    "params = model.parameters\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Define a checkpoints dictionary and perform some simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* A checkpoint is part of the original McGee code, where a policy change can be implemented. In this case: a policy change at the 20th of April 2020, where the interaction is altered: 0.3 * home interaction, 0.09 * work interaction, 0.12 * transportation interaction.\n",
    "* Check `model.sim?` for information on the simulation. The default starting date is 2020-03-15. Runs till September 21st\n",
    "* *Question*: what does `excess_time` mean, and how should I read the plot? Not sure what I'm looking at.\n",
    "* *Question* The results differ (more than) an *order of magnitude* in peak value. That's huge! Are these results at all useful? Note how the measures efficiently bring $R_0$ down under 1, causing new infections to die out fast.\n",
    "* *Question*: Why does the `out` dataset have a time dimension of 241? I thought the model only runs between 15 March and 21 September.\n",
    "* `NIS` dimension has been changed to `place` dimension (name change)\n",
    "\n",
    "* Also interesting (and expected): if we introduce more initial cases, chances of the infection dying out by chance are very slim, so the resulting time series will be more similar.\n",
    "* *Question*: where do the fluctuations on a single line come from? The only parameter change happens at 20 april."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.267005Z",
     "start_time": "2020-10-07T10:35:30.118Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Age-stratified\n",
    "Ninit_dummy, Nc_home, Nc_work, Nc_school, Nc_transport, Nc_leisure, Nc_others, Nc_total = polymod.get_interaction_matrices()\n",
    "\n",
    "# Not age-stratified\n",
    "# # this sums to 11.25\n",
    "# Nc_home = 3.21\n",
    "# Nc_work = 2.05\n",
    "# Nc_school = 0.95\n",
    "# Nc_transport = 0.41\n",
    "# Nc_leisure = 2.3\n",
    "# Nc_others = 2.33\n",
    "\n",
    "chk = {\n",
    "    'time': ['20-04-2020'],\n",
    "    'Nc':   [0.3*(1.0*Nc_home + 0.3*Nc_work + 0.4*Nc_transport)]\n",
    "}\n",
    "\n",
    "\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.267005Z",
     "start_time": "2020-10-07T10:35:30.120Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note: this is computationally expensive\n",
    "\n",
    "# Run the model 20 times, sum over all age classes and arrondissements, show the new hospitalisations\n",
    "fig,ax=plt.subplots()\n",
    "for i in range(2):\n",
    "    out=model.sim('21-09-2020',excess_time=50,checkpoints=chk)\n",
    "    # Select this one for the sum of all NIS codes\n",
    "    #sumNIS=out.sum(dim=\"place\").sum(dim=\"Nc\")\n",
    "    # Select this one for only NIS==21000\n",
    "    sumNIS=out.sel(place=21000).sum(dim='Nc')\n",
    "    plt.plot(out[\"time\"].values,sumNIS[\"H_in\"].values,alpha=0.5,color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualisation on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Read the arrondissements shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.268003Z",
     "start_time": "2020-10-07T10:35:30.122Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load different geographical aggregations\n",
    "country = gp.read_file(\"../../data/raw/geopandas/BE/AD_6_Country.shp\") # 1 entry\n",
    "regions = gp.read_file(\"../../data/raw/geopandas/BE/AD_5_Region.shp\") # 3 entries\n",
    "provinces = gp.read_file(\"../../data/raw/geopandas/BE/AD_4_Province.shp\") # 11 entries\n",
    "arrondissements = gp.read_file(\"../../data/raw/geopandas/BE/AD_3_District.shp\") # 43 entries\n",
    "municipalities = gp.read_file(\"../../data/raw/geopandas/BE/AD_2_Municipality.shp\") # 581 entries\n",
    "\n",
    "municipalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Perform a single simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Comments Michiel\n",
    "* Again note that different simulations give *very* different results (more than order of magnitude difference)! Run code below a couple of time to see this.\n",
    "* The plot below shows whether the pandemic was 'serious': it shows whether it is worth making a gif from\n",
    "* In images the cumulative data is shown. In the plot below as well.\n",
    "* The statement `out.sum(dim=\"Nc\")['M'][:,day]` can be made more efficient with cumsumNIS_M (but not really necessary)\n",
    "* x100 in `data2plot` because we want to show the percentage\n",
    "* `norm=colors.LogNorm`: Normalize a given value to the 0-1 range on a log scale.\n",
    "* I'm not sure what the difference is between the first frame and the other frames (legend on/off?)\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.269001Z",
     "start_time": "2020-10-07T10:35:30.123Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# simulation for 250 days (after March 15th) with the measure changes defined above\n",
    "out=model.sim(250,checkpoints=chk)\n",
    "\n",
    "# Again sum over all ages and arrondissements, and show people that are mildly affected on a national level\n",
    "sumNIS=out.sum(dim=\"place\").sum(dim=\"Nc\")\n",
    "cumsumNIS_M = np.cumsum(sumNIS[\"M\"]) # sumNIS[\"M\"]\n",
    "plt.plot(out[\"time\"], cumsumNIS_M, alpha=0.5, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.269998Z",
     "start_time": "2020-10-07T10:35:30.124Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_path = 'results/maps'\n",
    "\n",
    "# create the plot\n",
    "fig, ax = plt.subplots(figsize = (12,12)) # 12 inches x 12 inches\n",
    "\n",
    "start = 0\n",
    "\n",
    "# Create daily images for a .gif\n",
    "for day in range(start,len(out['time'].values)):\n",
    "    # Get data\n",
    "    # Sum over age classes (not interested in those yet) and show the percentage of mildly symptomatic people\n",
    "    data2plot = out.sum(dim=\"Nc\")['M'][:,day].values / initN_df['total'].values*100\n",
    "    \n",
    "    # Make new 'data' column with the cumulative mildly symptomatic people that is updated every iteration\n",
    "    arrondissementen['data'] = data2plot\n",
    "    \n",
    "    # Visualize data\n",
    "    # Only produce a legend in the first frame?\n",
    "    if day == start:\n",
    "        fig = arrondissementen.plot(column = 'data', ax=ax, cmap='plasma',\n",
    "                                    norm=colors.LogNorm(vmin=0.001, vmax=1), legend=True, edgecolor = 'k')\n",
    "    else:\n",
    "        fig = arrondissementen.plot(column = 'data', ax=ax, cmap='plasma',\n",
    "                                    norm=colors.LogNorm(vmin=0.001, vmax=1), legend=False, edgecolor = 'k')\n",
    "    # Disable axis\n",
    "    ax.set_axis_off()\n",
    "    # This will save the figure as a high-res png in the output path. You can also save as svg if you prefer.\n",
    "    chart = fig.get_figure()\n",
    "    #chart.savefig(output_path + str(day) + '_B.jpg' ,dpi=100)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:35:30.270995Z",
     "start_time": "2020-10-07T10:35:30.126Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "fig.set_size_inches(16, 4)\n",
    "ax.plot(out['time'][50:200],out.sel(place=name2nis('arrondissement antwerpen')).sum(dim='Nc')['M'][50:200],color='blue',alpha=0.40)\n",
    "ax.plot(out['time'][50:200],out.sel(place=name2nis('arrondissement La LouviÃ¨re')).sum(dim='Nc')['M'][50:200],color='red',alpha=0.40)\n",
    "ax.plot(out['time'][50:200],out.sel(place=name2nis('arrondissement luik')).sum(dim='Nc')['M'][50:200],color='black',alpha=0.40)\n",
    "ax.legend(['Antwerp','Brussels','Luik'])\n",
    "ax.axvline(130,color='black',linestyle='dashed')\n",
    "ax.set_title('Daily hospitalizations $(H_{in})$')\n",
    "fig.savefig('daily_hosp.jpg',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-07T14:54:25.772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load SEIRD parameters and polymod parameters\n",
    "spatial = 'arr'\n",
    "intensity = 'all'\n",
    "\n",
    "params = model_parameters.get_COVID19_SEIRD_parameters(age_stratified=True, spatial=spatial)\n",
    "initN, Nc_home, Nc_work, Nc_schools, Nc_transport, Nc_leisure, Nc_others, Nc_total = model_parameters.get_interaction_matrices(intensity=intensity, spatial=spatial)\n",
    "\n",
    "# Set initial states\n",
    "E = 5*np.ones(initN.shape)\n",
    "initial_states = {'S': initN, 'E': E}\n",
    "\n",
    "# Add the delayed ramp parameters and the social_policy_func parameters to the parameter dictionary.\n",
    "params.update({'ll': 20,\n",
    "              'tau': 0})\n",
    "params.update({'policy1': Nc_total, # No restrictions\n",
    "          'policy2': Nc_home, # Everyone in home isolation\n",
    "          'policy_time': 40})\n",
    "\n",
    "\n",
    "# Define the social policy function\n",
    "def social_policy_func(t,param,policy_time,policy1,policy2,ll,tau):\n",
    "    if t < policy_time:\n",
    "        return policy1\n",
    "    else:\n",
    "        tt = t-policy_time\n",
    "        if tt <= tau:\n",
    "            return policy1\n",
    "        if (tt > tau) & (tt <= tau + ll):\n",
    "            intermediate = (policy2 - policy1) / ll * (tt - tau) + policy1\n",
    "            return intermediate\n",
    "        if tt > tau + ll:\n",
    "            return policy2\n",
    "    \n",
    "# Load the model\n",
    "model = models.COVID19_SEIRD_sto_spatial(initial_states, params, time_dependent_parameters={'Nc' : social_policy_func},\n",
    "                                         discrete=True)\n",
    "\n",
    "# Shows parameters that are loaded into the model\n",
    "model.parameters\n",
    "\n",
    "# Shows parameters that will change over time due to policies\n",
    "model.time_dependent_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T14:46:06.299907Z",
     "start_time": "2020-10-07T14:45:44.783567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.70501355857687\n",
      "7.357800660601535\n",
      "7.0105877626262\n",
      "6.663374864650865\n",
      "6.31616196667553\n",
      "5.968949068700194\n",
      "5.621736170724859\n",
      "5.274523272749525\n",
      "4.927310374774189\n",
      "4.580097476798853\n",
      "4.232884578823518\n",
      "3.8856716808481835\n",
      "3.5384587828728487\n",
      "3.191245884897513\n",
      "2.844032986922178\n",
      "2.4968200889468424\n",
      "2.1496071909715075\n",
      "1.8023942929961727\n",
      "1.455181395020837\n",
      "1.1079684970455022\n",
      "0.7607555990701664\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n",
      "0.760755599070166\n"
     ]
    }
   ],
   "source": [
    "start = '2020-03-01'\n",
    "stop = '2020-06-15'\n",
    "\n",
    "out = model.sim(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T10:41:09.373784Z",
     "start_time": "2020-10-07T10:41:09.294031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test where the probability goes over 1 // under 0\n",
    "spatial = 'prov'\n",
    "mobility = 1\n",
    "\n",
    "params = model_parameters.get_COVID19_SEIRD_parameters(age_stratified=True, spatial=spatial)\n",
    "initN, Nc_home, Nc_work, Nc_schools, Nc_transport, Nc_leisure, Nc_others, Nc_total = polymod.get_interaction_matrices(spatial=spatial)\n",
    "\n",
    "G = params['place'].shape[0] # spatial stratification\n",
    "N = params['Nc'].shape[0] # age stratification\n",
    "\n",
    "params['pi'] = np.ones(N) * mobility\n",
    "\n",
    "l = 1.0 # timestep\n",
    "n = 1 # number of draws\n",
    "\n",
    "# If 1e3 is changed to 1e20 we would expect the probability to go to unity, but it does not.\n",
    "I = 0*np.ones([G,N])\n",
    "A = 0*np.ones([G,N])\n",
    "M = np.zeros([G,N])\n",
    "ER = np.zeros([G,N])\n",
    "C = np.zeros([G,N])\n",
    "ICU = np.zeros([G,N])\n",
    "C_icurec = np.zeros([G,N])\n",
    "R = np.zeros([G,N])\n",
    "D = np.zeros([G,N])\n",
    "S = initN\n",
    "E = np.ones([G,N])\n",
    "T = I + A + M + ER + C + ICU + C_icurec + R + D + S + E\n",
    "\n",
    "# Define hospitalisations\n",
    "H_in = np.zeros([G,N])\n",
    "H_out = np.zeros([G,N])\n",
    "H_tot = np.zeros([G,N])\n",
    "\n",
    "\n",
    "T_eff = np.zeros([G,N]) # initialise\n",
    "A_eff = np.zeros([G,N])\n",
    "I_eff = np.zeros([G,N])\n",
    "for g in range(G):\n",
    "    for i in range(N):\n",
    "        sumT = 0\n",
    "        sumA = 0\n",
    "        sumI = 0\n",
    "        for h in range(G):\n",
    "            term1 = (1 - params['pi'][i]) * np.identity(G)[h][g]\n",
    "            term2 = params['pi'][i] * params['place'][h][g]\n",
    "            sumT += (term1 + term2) * T[h][i]\n",
    "            sumA += (term1 + term2) * A[h][i]\n",
    "            sumI += (term1 + term2) * I[h][i]\n",
    "        T_eff[g][i] = sumT\n",
    "        A_eff[g][i] = sumA\n",
    "        I_eff[g][i] = sumI\n",
    "\n",
    "\n",
    "# Density dependence per patch: f[patch]\n",
    "xi = 0.01 # km^-2\n",
    "T_eff_total = T_eff.sum(axis=1)\n",
    "rho = T_eff_total / params['area']\n",
    "f = 1 + (1 - np.exp(-xi * rho))\n",
    "\n",
    "# Normalisation factor per age class: zi[age]\n",
    "# Population per age class\n",
    "Ti = T.sum(axis=0)\n",
    "denom = np.zeros(N)\n",
    "for h in range(G):\n",
    "    value = f[h] * T_eff[h]\n",
    "    denom += value\n",
    "zi = Ti / denom\n",
    "\n",
    "# The probability to get infected in the 'home patch' when in a particular age class: P[patch][age]\n",
    "# initialisation for the summation over all ages below\n",
    "argument = np.zeros([G,N])\n",
    "for i in range(N):\n",
    "    for g in range(G):\n",
    "        summ = 0\n",
    "        for j in range(N):\n",
    "            term = - params['beta'] * params['s'][i] * zi[i] * f[g] * params['Nc'][i,j] * (I_eff[g,j] + A_eff[g,j]) / T_eff[g,j]\n",
    "            summ += term\n",
    "        argument[g,i] = summ\n",
    "P = 1 - np.exp(l * argument) # multiplied by length of timestep\n",
    "\n",
    "# The probability to get infected in any patch when in a particular age class: Pbis[patch][age]\n",
    "Pbis = np.zeros([G,N]) # initialise\n",
    "# THIS NEEDS TO BE CHANGED if PLACE BECOMES AGE-STRATIFIED\n",
    "for i in range(N):\n",
    "    for g in range(G):\n",
    "        summ = 0\n",
    "        for h in range(G):\n",
    "            term = params['place'][g,h] * P[h,i]\n",
    "            summ += term\n",
    "        Pbis[g,i] = summ\n",
    "\n",
    "# The total probability bigP[patch][age], depending on mobility parameter pi[age]\n",
    "bigP = np.zeros([G,N])\n",
    "for i in range(N):\n",
    "    for g in range(G):\n",
    "        bigP[g,i] = (1 - params['pi'][i]) * P[g,i] + params['pi'][i] * Pbis[g,i]\n",
    "\n",
    "\n",
    "# To be added: effect of average family size (sigma^g or sg)\n",
    "\n",
    "\n",
    "# Make a dictionary containing the propensities of the system\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "keys = ['StoE','EtoI','ItoA','ItoM','AtoR','MtoR','MtoER','ERtoC','ERtoICU','CtoR','ICUtoCicurec','CicurectoR','CtoD','ICUtoD','RtoS']\n",
    "\n",
    "\n",
    "# Probabilities for a single agent to migrate between SEIR compartments in one unit of the timestep (typically days)\n",
    "probabilities = [bigP,\n",
    "                (1 - np.exp(- l * (1/params['sigma']) ))*np.ones([G,N]),\n",
    "                1 - np.exp(- l * params['a'] * (1/params['omega']) )*np.ones([G,N]),\n",
    "                1 - np.exp(- l * (1-params['a'])* (1/params['omega']) )*np.ones([G,N]),\n",
    "                (1 - np.exp(- l * (1/params['da']) ))*np.ones([G,N]),\n",
    "                (1 - np.exp(- l * (1-params['h'])* (1/params['dm']) ))*np.ones([G,N]),\n",
    "                1 - np.exp(- l * params['h'] * (1/params['dhospital']) )*np.ones([G,N]),\n",
    "                1 - np.exp(- l * params['c'] * (1/params['der']) )*np.ones([G,N]),\n",
    "                1 - np.exp(- l * (1-params['c']) * (1/params['der']) )*np.ones([G,N]),\n",
    "                (1 - np.exp(- l * (1-params['m_C']) * (1/params['dc_R']) ))*np.ones([G,N]), ###\n",
    "                (1 - np.exp(- l * (1-params['m_ICU']) * (1/params['dICU_R']) ))*np.ones([G,N]),\n",
    "                (1 - np.exp(- l * (1/params['dICUrec']) ))*np.ones([G,N]),\n",
    "                (1 - np.exp(- l * params['m_C'] * (1/params['dc_D']) ))*np.ones([G,N]),\n",
    "                (1 - np.exp(- l * params['m_ICU'] * (1/params['dICU_D']) ))*np.ones([G,N]),\n",
    "                (1 - np.exp(- l * params['zeta'] ))*np.ones([G,N]),\n",
    "                ]\n",
    "\n",
    "\n",
    "states = [S, E, I, I, A, M, M, ER, ER, C, ICU, C_icurec, C, ICU, R]\n",
    "propensity={}\n",
    "# Calculate propensity for each migration (listed in keys)\n",
    "for k in range(len(keys)):\n",
    "    prop=np.zeros([G,N])\n",
    "    for g in range(G):\n",
    "        for i in range(N):\n",
    "            # If state is empty, no one can migrate out of it\n",
    "            if states[k][g][i]<=0:\n",
    "                prop[g,i]=0\n",
    "            else:\n",
    "                draw=np.array([])\n",
    "                # Loop over number of draws. Calculate binomial random number per draw and pick average\n",
    "                for l in range(n):\n",
    "                    draw = np.append(draw,np.random.binomial(states[k][g][i],probabilities[k][g][i]))\n",
    "                draw = np.rint(np.mean(draw)) # round to nearest integer\n",
    "                prop[g,i] = draw\n",
    "    # Define migration flow\n",
    "    propensity.update({keys[k]: np.asarray(prop)})\n",
    "\n",
    "\n",
    "S  = S - propensity['StoE'] + propensity['RtoS']\n",
    "E  =  E + propensity['StoE'] - propensity['EtoI']\n",
    "I =  I + propensity['EtoI'] - propensity['ItoA'] - propensity['ItoM']\n",
    "A =  A + propensity['ItoA'] - propensity['AtoR']\n",
    "M =  M + propensity['ItoM'] - propensity['MtoR'] - propensity['MtoER']\n",
    "ER = ER + propensity['MtoER'] - propensity['ERtoC'] - propensity['ERtoICU']\n",
    "C =  C + propensity['ERtoC'] - propensity['CtoR'] - propensity['CtoD']\n",
    "C_icurec =  C_icurec + propensity['ICUtoCicurec'] - propensity['CicurectoR']\n",
    "ICU =  ICU +  propensity['ERtoICU'] - propensity['ICUtoCicurec'] - propensity['ICUtoD']\n",
    "R =  R + propensity['AtoR'] + propensity['MtoR'] + propensity['CtoR'] + propensity['CicurectoR'] - propensity['RtoS']\n",
    "D = D +  propensity['ICUtoD'] +  propensity['CtoD']\n",
    "H_in = propensity['ERtoC'] + propensity['ERtoICU']\n",
    "H_out = propensity['CtoR'] + propensity['CicurectoR']\n",
    "H_tot = H_tot + H_in_new - H_out_new - propensity['ICUtoD'] -  propensity['CtoD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T15:59:17.113710Z",
     "start_time": "2020-10-07T15:59:16.732586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10)       1269068\n",
       "[10, 20)      1300254\n",
       "[20, 30)      1407645\n",
       "[30, 40)      1492290\n",
       "[40, 50)      1504539\n",
       "[50, 60)      1590628\n",
       "[60, 70)      1347139\n",
       "[70, 80)       924291\n",
       "[80, 110)      656787\n",
       "total        11492641\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Big file -- takes a while\n",
    "# raw_df = pd.read_excel(\"../../data/raw/interaction_matrices/demographic/TF_SOC_POP_STRUCT_2020.xlsx\")\n",
    "# -----------------\n",
    "\n",
    "age_lims = [10,20,30,40,50,60,70,80]\n",
    "age_names = [\"[0, 10)\",\"[10, 20)\",\"[20, 30)\",\"[30, 40)\",\"[40, 50)\",\"[50, 60)\",\"[60, 70)\",\"[70, 80)\",\"[80, 110)\",\"total\"]\n",
    "\n",
    "\n",
    "\n",
    "NIS_list_df = pd.read_csv(\"../../data/interim/census_2011/census-2011-updated_row-commutes-to-column_prov.csv\")\n",
    "NIS_list = NIS_list_df['NIS'].sort_index().values\n",
    "\n",
    "\n",
    "initN_prov = np.zeros([len(NIS_list), len(age_lims) + 2], dtype=int)\n",
    "for g in range(len(NIS_list)):\n",
    "    nis = NIS_list[g]\n",
    "    region = raw_df[raw_df['CD_PROV_REFNIS']==nis]\n",
    "    for i in range(len(age_lims)):\n",
    "        age = age_lims[i]\n",
    "        region_age = region[(region['CD_AGE'] < age) & (region['CD_AGE'] >= age - 10)]\n",
    "        pop = region_age['MS_POPULATION'].sum(axis=0)\n",
    "        initN_prov[g,i] = pop\n",
    "    region_old = region[(region['CD_AGE'] >= 80)]\n",
    "    pop = region_old['MS_POPULATION'].sum(axis=0)\n",
    "    initN_prov[g,-2] = pop\n",
    "    initN_prov[g,-1] = initN_prov[g,:-1].sum()\n",
    "    if nis == 21000:\n",
    "        region = raw_df[raw_df['CD_DSTR_REFNIS']==nis]\n",
    "        for i in range(len(age_lims)):\n",
    "            age = age_lims[i]\n",
    "            region_age = region[(region['CD_AGE'] < age) & (region['CD_AGE'] >= age - 10)]\n",
    "            pop = region_age['MS_POPULATION'].sum(axis=0)\n",
    "            initN_prov[g,i] = pop\n",
    "        region_old = region[(region['CD_AGE'] >= 80)]\n",
    "        pop = region_old['MS_POPULATION'].sum(axis=0)\n",
    "        initN_prov[g,-2] = pop\n",
    "        initN_prov[g,-1] = initN_prov[g,:-1].sum()\n",
    "    \n",
    "initN_prov_df = pd.DataFrame(initN_prov, columns=age_names, index=NIS_list)\n",
    "initN_prov_df.index.name = 'NIS'\n",
    "\n",
    "initN_prov_df.sum()\n",
    "\n",
    "# initN_prov_df.to_csv(\"initN_prov.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
